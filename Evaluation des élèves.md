![[ISEF - Chapitre 6 14 11 2024.pdf]]

Effet de contraste: 
corriger un faible après un fort: $\downarrow$
corriger un fort après un faible: $\uparrow$

Copie corrigée vers les derniers: $\downarrow$

L'évaluation est **nécessaire**. 

**Deux faces**: 
	peut aider les élèves à apprendre mais va enfermer les enfants dans une situation d'échecs, désagréable.

$+$ : peut soutenir les apprentissages
$-$ : l'évaluation sert à classer, à créer des hiérarchies de succès

# Types d'évaluation
**Evaluation formative**: tests pour permettre de se situer dans les apprentissages courants sans pour autant que les points soient comptabilisés. Doit aussi aider l'enseignant à guider son enseignement.
**Evaluation sommative**: établir un bilan certifiant. Voir si les compétences visées dans le programme sont atteintes.
**Evaluation pronostique**: anticipe les apprentissages qui seront abordés ultérieurement.


**Erreurs d'utilisation:**
- Les épreuves sommatives ne devraient pas être utilisées pour déterminer les capacités d'un élève et son futur (il a raté à ce test donc il n'aura surement pas le niveau pour venir à notre école).
- On ne peut pas utiliser un test formatif et soudainement le compter pour le bulletin.

Les évaluations actuellement évaluent les élèves les uns par rapport aux autres.

**Perspective normative** - perspective d'excellence
Dans la perspective normative, on va classer les élèves. A grande échelle, ça pourrait être représenté sur une courbe de Gauss (cons - faibles - moyens - intelligents - génies).
On va classer les élèves au sein d'un petit environnement non-représentatif de la réalité.

Evaluation à fonction normative: logique d'**évaluation pronostique** - est-ce que l'élève sera capable de réussir l'année suivante avec ce qu'il a appris?
Si on est dans une logique pronostique, il est logique de faire des questions difficiles, **discriminantes** et de classer les élèves - **logique sélective**.

Mauvaise utilisation de l'évaluation pronostique en lien avec la logique sélective.

**Perspective de la maitrise**
Bloom. On veut travailler pour que la majorité atteigne les objectifs.
S'oppose à la perspective de l'excellence.
- Evaluation sommatives à références sommative critériée
	- Exemple grille évaluation CEB
	![[Pasted image 20241114161823.png|450]]
- Evaluation formative

A Grisay voulait voir si il y avait une cohérence entre les examens qu'ont fait passer les chercheurs et les examens qu'ont fait passer les enseignants.

Les chercheurs ont remis les résultats des tests sur une note Z qui permettra de comparer les résultats des deux types de tests. 
Z > 0: plus grand que la moyenne
Z < 0: plus petit que la moyenne
Ecart type: comment les notes se distribuent autour de la moyenne

Il faut savoir calculer le score Z! #tuyau

$Z = \dfrac{X-M}{S}$

Exemple: score de 120, moyenne de 100, écart type de 10.
Z = (120 - 100)/10 = 2

![[Pasted image 20241114164117.png]]

Selon la façon dont les notes ont été données, les variations peuvent être plus ou moins importantes. 
Les performances des élèves sont **plus homogènes** quand elles sont mesurées avec un test de chercheur - **test externe**. #tuyau 
Les performances des chercheurs sont plus hétérogènes quand elles sont mesurées par les enseignants. #tuyau
Les compétences des élèves sont bien plus proches les unes des autres quand elles sont mesurées par des tests de chercheurs et les différences explosent quand évaluées par les enseignants.
=> **Les professeurs créent des variances importantes entre les élèves alors que les tests de chercheurs ont une variété de notes bien plus réduites. Le mécanisme d'évaluation en classe maximise les différences.**

Les amplifications des résultats peuvent faire doubler des élèves qui n'auraient pas doublé si testés autrement.


